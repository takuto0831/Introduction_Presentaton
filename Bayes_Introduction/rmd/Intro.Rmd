---
title: "Bayes Inference Introduction"
date: "`r Sys.Date()`"
author: "Takuto Kotsubo"
output:
  ioslides_presentation:
    widescreen: true
editor_options: 
  chunk_output_type: console
---

```{r set up, message=FALSE,echo=FALSE}
# Global options
library(knitr)
opts_chunk$set(message = FALSE)
opts_knit$set(width=75)
# setting directory
setwd("~/Desktop/Intro_pres/Bayes_Introduction/")
# ggplot setting
library(tidyverse)
theme_set(theme_classic(base_size = 18,base_family = "Helvetica"))
```

```{r stan option, message=FALSE,echo=FALSE}
library(ggmcmc)
library(rstan)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

# 第1章: ベイズ統計

## ベイズ統計とは?

- データだけでなく, データの背後にある要素(パラメータなど)も確率的に生成されると仮定する.

## 信頼区間と信用区間?

- 信頼区間(confidence interval): 95%信頼区間は, 標本抽出して95%信頼区間を計算するという操作を100回繰り返した時に, そのうち95回はその区間に母平均が含まれるような区間のこと.

- 信用区間(credible interval): 母平均の事後確率分布において, 真の値が95%の確率で含まれる区間のこと.

**信用区間はベイズ主義の考えに基づく(ベイズ主義:パラメータも確率分布から生成されると考える)**

## 最尤推定の関係性

- ベイズの枠組みでは$X$の事後分布$p(x|y)$そのものが答えとなるが, 一つの推定値を答えとしたい場合, 事後分布$p(x|y)$, もしくは$p(y|x)p(x)$を最大にする$x=x^*$を推定値とする**(MAP推定値)**

- 事前分布$p(x)$が無情報事前分布などであれば, MAP推定値は, $p(y|x)$を最大にする$x=x^*$を推定値とする**(最尤法)**によるパラメータ推定とほぼ一致する.

## MCMCとMAP推定値

- MCMCはMAP推定値との相性があまりよくない. MCMCは事後分布からのサンプリングのための道具であって, 最適化手法では無い!

- MCMCを使う場合に, 一つの推定値を求める場合には, 事後分布による期待値や目的変数の周辺分布の中央値やモードを用いる. (なんでだろう??)

# 階層ベイズ

## 階層ベイズとは?

- パラメータ$X$の値が確率分布$p(x)$から生成され, 次にデータ$Y$の値が$p(y|x)$から生成され, という様な二段階の生成過程を, さらに多段階化して考えること！

- $Y_{ij}$: 各店舗($i$), 各人の売り上げ($j$), $X_i$: 店舗($i$)の売り上げ, $W_1$: 店舗全体の平均値, $W_2$: 店舗間の分散,$S$: $W_1,W_2$の事前分布を決めるパラメータと設定した場合, 

**S -> W -> X -> Y**というような生成過程を仮定する.

## 実行例: 給食の種類によって, 成績が変わるのか？

- 仮想データを使用して, 階層ベイズを試してみる.
- pref: 県, N: 対象者数, mean.Y: 対象者の平均身長, sd.Y: 対象者の身長の標準偏差, Age: 測定の回数(0,1), X: 給食タイプ(0,1)

```{r}
library(tidyverse)
load(file = "~/Desktop/Intro_pres/Bayes_Introduction/data/data.Rdata")
dplyr::glimpse(d)
```

## データ概要

```{r}
ggplot(d,aes(x=factor(Age), y=mean.Y, colour = pref,group = pref)) +
  geom_point(aes(shape = factor(X))) + geom_line() + theme_classic()
```

## 一般化線形モデル

$$mean.Y = \beta_1 + \beta_2 A_i + \beta_3 A_i X_j$$

**「乙タイプの給食を食べている学校の方が乙タイプの学校よりもおよそ1.72低い??」**

```{r}
d %>% glm(mean.Y ~ 1 + Age + Age:X, data = .) %>% 
  broom::tidy() %>% 
  knitr::kable(format = "markdown", digits = 4)
```

## Rstanでベイズモデル

```{r}
# data
d_list <- list(N = 2,
               N_pref = length(unique(d$pref)), # データにおける都道府県の数
               Mean_Y = t(matrix(d$mean.Y, length(unique(d$pref)), 2)),
               Sigma_Y = t(matrix(d$sd.Y/sqrt(d$N), length(unique(d$pref)), 2)), # dim() 2 10... N_r  N_pref
               X = t(matrix(d$X, length(unique(d$pref)), 2)),
               Age = t(matrix(d$Age, length(unique(d$pref)), 2)))
# コンパイル
model <- stan_model("stan/bayes_model.stan")
# サンプリング
fit <- rstan::sampling(object = model,
                       data = d_list,
                       verbose = TRUE, 
                       iter = 3000, 
                       chains = 3)
```

## 収束性の確認

```{r}
fit %>% traceplot()
```

## ggmcmc package

- plot

```{r}
df_param <- ggs(fit)
p1 <- ggs_histogram(df_param)
p2 <- ggs_autocorrelation(df_param)
p3 <- ggs_geweke(df_param) # Gewekeの診断方法
p4 <- ggs_Rhat(df_param) + xlab("R_hat") # 各パラメータのRhatのばらつき
gridExtra::grid.arrange(p1, p2, p3, p4, ncol = 2)
```

- パラメータの信用区間

```{r}
ci(df_param) %>% knitr::kable(digits = 4)
```


# 第5章: まとめ

## 参考文献

1. 松浦健太郎(2016), 「StanとRでベイズ統計モデリング」共立出版株式会社.
1. Gelman, A. (2013). *Bayesian Data Analysis, Third Edition*. Chapman and Hall/CRC. 
1. Stan Development Team, Stan Modeling Language User’s Guide and Reference Manual, https://github.com/stan-dev/stan/releases/download/v2.17.0/stan-reference-2.17.0.pdf
